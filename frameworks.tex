\section*{Una panoramica}
In questo ultimo capitolo passiamo in rassegna i framework esistenti per l'implementazione di reti neurali. Grazie a loro  lo sviluppo di modelli e il processo di acquisizione dati per l'allenamento dei dati diventa molto più facile e accessibile rispetto ad un tempo. 
\section*{Tensorflow}
METTERE LE CITAZIONI QUI[doc tf, wiki tf, doc keras]
Tensorflow  fu creato dal team Brain Google come successore di un precedente sistema per il machine learning conosciuto come \textit{DistBelief} con l'intento di ristrutturare il codice rendendola una libreria più robusta. Venne distribuita come progetto open-source nel 2015 e si presenta come una libreria per linguaggi come Python, Javascript, Swift e Java per Android  e le librerie a cui fa a sua volta ricorso per l'implementazione delle parti più critiche sono scritte in C++. \textit{TF} offre compatibilità con le API d'alto livello di \textit{Keras}; esse consentono grazie alla loro modularità e facilità di utilizzo di eseguire velocemente la prototipizzazione di modelli e la sperimentazione delle reti neurali su piattaforme diverse e renderle velocemente funzionanti per il testing.

Tensorflow rappresenta le computazioni come dei dei grafi i quali sono composti da due tipi di oggetti: le operazioni, ovvero i nodi del grafo e i tensori, dal cui utilizzo prende il nome, che sarebbero gli archi del grafo.
I tensori sono matrici multidimensionali su cui vengono fatti i calcoli e che contengono i parametri della rete.

Tensorflow gira sia su CPU che GPU, grazie alle librerie di programmazione per schede grafiche \textit{CUDA} e \textit{Open CL}. Per la sua applicazione specifica è stato progettato da Google un processore dedicato chiamato \textit{TPU}. L'interesse verso un processore dedicato non tanto all'allenamento della rete quanto al suo utlizzo rappresenta un vantaggio per l'applicazione dell'intelligenza artificiale in quegli ambiti dove si predilige una velocità di esecuzione; un esempio può essere un chip dedicato in un dispositivo cellulare, che rende più efficiente determinati task, come il riconoscimento vocale o facciale per quelle applicazioni che ne fanno uso. Google stessà dichiarò che il suo utilizzo nei datacenter aveva ottimizzato le performance di un ordine di grandezza, riducendo il dispendio energetico derivato dal loro utilizzo. 

\section*{PyTorch}
