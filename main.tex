\documentclass [12pt,oneside,a4paper,openany]{book}
\special{papersize=210mm,297mm}
\setlength{\topmargin}{0in}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{graphicx,wrapfig,lipsum}
\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage[paper=a4paper,margin=1in]{geometry}
\usepackage{cite}
\usepackage{subfig}
\usepackage{float}
\usepackage{titlesec}
\renewcommand{\baselinestretch}{1.25}

%PACCHETTI PER LA MATEMATICA
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}

\fboxsep=10mm%padding thickness
\fboxrule=4pt%border thickness

\begin{document}



\title{Reti neurali: dall'algoritmo di back propagation alle reti profonde }
\author{Alessandro Sassi}
\date{Today}

\titlespacing*{\section}
{0pt}{5.5ex plus 1ex minus .2ex}{4.3ex plus .2ex}
\titlespacing*{\subsection}
{0pt}{5.5ex plus 1ex minus .2ex}{4.3ex plus .2ex}



\input{frontespizio}


\tableofcontents
\chapter{Introduzione}
\input{intro}
\chapter{L'algoritmo di Backpropagation }
\input{bp}
\chapter{I framework per le reti neurali}
\input{frameworks}

\chapter{Conclusioni}
In questa overview sulla tecnologia delle reti neurali abbiamo visto la loro storia e la loro ispirazione, abbiamo visto le librerie software che ci permettono di implementarle e di creare applicazioni utili in moltissimi campi. Il protagonista rimane però l'algoritmo di backpropagation che consente a queste reti di apprendere. Dalla definizione dell'algoritmo di backpropagation alle reti neurali profonde sono passati tre decenni, e le applicazioni attuali fanno uso di sviluppi nel campo dell'hardware che sono stati possibili solo di recente. Negli ultimi anni grazie a questo algoritmo e alle reti neurali abbiamo potuto raggiungere risultati strabilianti, in tutti i campi del sapere, dalla medicina all'ingegneria.

Ora ci chiediamo quali altri sviluppi ci aspettino. Uno dei suoi ideatori è dell'opinione che forse, potremmo aver già ottenuto quanto possibile da questa tecnologia e che oltre a piccoli miglioramenti non potremo andare. Avremmo secondo Hinton, lo scienziato che si è pronunciato sugli sviluppi futuri di questo settore, raggiunto una sorta di plateau per il progresso nell'intelligenza artificiale. A suo modo di vedere, backpropagation, che nacque ispirandosi a come gli animali imparano, attraverso prove ed errori, rappresenterebbe un'intelligenza che mima quella umana, ma soltanto superficialmente; e lo dimostrebbe la facilità con cui possono essere messi in crisi sistemi intelligenti come quelli che abbiamo oggi, basterebbe modificare di poco le richieste del problema a cui lavorano per farli fallire. L'intelligenza umana è lontana dall'essere rappresentata in quella che è la sua flessibilità e velocità nell'apprendere a partire da pochi dati essenziali. Un esempio: una rete richiede di essere allenata con magari 40 milioni di immagini di un certo soggetto per imparare a riconoscerlo mentre un bambino che impara a riconoscere un gelato avrà bisogno di vederlo anche una sola volta per fare la corretta generalizzazione. 

Sempre secondo Hinton siamo lontani da una vera intelligenza poiché non è stato ancora compreso a fondo quale sia il vero funzionamento del nostro cervello. Soltanto quando saremo riusciti a creare un ponte fra neuroscienze e i computer potremo dire di avere una reale intelligenza artificiale. Nel frattempo dovremo rimettere in discussione tutto quello che è stato raggiunto fino ad oggi con backpropagation, ripensando l'apprendimento come non supervisionato.

Per raggiungere risultati significativi dovremo aspettare che le idee rivoluzionarie come quella di Hinton e Rumelhart 30 anni fa maturino nei laboratori di ricerca, in attesa che le giuste condizioni si verifichino e rendano realtà un parallelo con la biologia che fin'ora è rimasto solo in superficie \cite{mit-ai}. 

\bibliographystyle{plain}
\bibliography{bib_ale}

\end{document}